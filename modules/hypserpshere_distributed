#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Oct  1 11:45:22 2022

@author: mlcv
"""
"""
Created on Mon Aug  9 21:03:27 2021

@author: hasan
"""
import datetime
import os
import time
import json
import torch
import torch.distributed as dist
import modules.utils_torchvision as utils
from modules.NirvanaLoss import center_loss_nirvana, nirvana_hypersphere
from torch.utils.tensorboard import SummaryWriter
import torchvision.models as models
from torchvision import transforms as T
from modules.utils_faceevolve import perform_val,get_val_data
from modules.utils import train_one_epoch, train_one_uhs, evaluate_majority_voting, evaluate_ijba_maj_vot, dataset_preperation
from Networks.model_irse import IR_50
from Networks.DAMNet import DAMGeneralNew
from Networks.iresnet_torch import iresnet100

os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'
os.environ["OMP_NUM_THREADS"]=str(4)

def train_one_uhs(
    model, 
    centerloss, 
    optimizer, 
    optimizer_center, 
    data_loader, 
    device, 
    epoch, 
    args
):
    model.train(), centerloss.train()
    metric_logger = utils.MetricLogger(delimiter="  ")
    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value}'))
    metric_logger.add_meter('img/s', utils.SmoothedValue(window_size=10, fmt='{value:.1f}'))
    header = 'Epoch: [{}]'.format(epoch)
    all_features, all_labels = [], []
    for image, target in metric_logger.log_every(data_loader, args.print_freq, header):
        start_time = time.time()
        image, target = image.to(device), target.to(device)
        
        if args.distributed:
            centers = centerloss.module.centers
        else:
            centers = centerloss.centers
        
        # extracting features from backbone and computing losses
        feats, _ = model(image)
        intraclass_loss, triplet_loss, uniform_loss = centerloss(feats, target)
        loss = 1.5 * intraclass_loss + 2.5 * triplet_loss + 0.25 * uniform_loss

        optimizer_center.zero_grad()
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        optimizer_center.step()

        all_features.append(feats.data.cpu().numpy())
        all_labels.append(target.data.cpu().numpy())
        acc1 = accuracy_l2_nosubcenter(feats,centers,target)

        batch_size = image.shape[0]
        metric_logger.update(loss=loss.item(),lr=optimizer.param_groups[0]["lr"])
        metric_logger.meters['acc1'].update(acc1.item(), n=batch_size)
        metric_logger.meters['img/s'].update(batch_size / (time.time() - start_time))
    
    metric_logger.synchronize_between_processes()
    # all_features = np.concatenate(all_features, 0)
    # all_labels = np.concatenate(all_labels, 0)
    print(' *Train Acc@1 {top1.global_avg:.3f} '
          .format(top1=metric_logger.acc1))

    return metric_logger.acc1.global_avg, metric_logger.loss.global_avg   

def evaluate_majority_voting(model, centerloss, data_loader, device, epoch, args):
    model.eval(), centerloss.eval()
    metric_logger = utils.MetricLogger(delimiter="  ")
    header = 'Test:'
    all_preds_l2,all_preds_l2_norm, all_labels, all_feats, all_dist_euc_cos = [], [], [], [], []
    
      
    with torch.no_grad():
        for image, target in metric_logger.log_every(data_loader, args.print_freq, header):
            image = image.to(device, non_blocking=True)
            target = target.to(device, non_blocking=True)
            feats, _ = model(image)
            
            if args.distributed:
                centers = centerloss.module.centers
            else:
                centers = centerloss.centers

            preds_l2 = get_l2_pred_nosubcenter(feats,centers, target)
            preds_l2_norm = cosine_similarity(feats,centers, target)
            dist_euc_cos = euc_cos(feats,centers, target)
            all_dist_euc_cos.append(dist_euc_cos.cpu())
            all_preds_l2.append(preds_l2.cpu())
            all_preds_l2_norm.append(preds_l2_norm.cpu())
            all_labels.append(target.cpu())
            all_feats.append(feats.cpu())

    preds_l2_norm = torch.cat(all_preds_l2_norm, 0)
    preds_l2 = torch.cat(all_preds_l2, 0)
    preds_euc_cos = torch.cat(all_dist_euc_cos, 0)
    labels = torch.cat(all_labels, 0)

    if args.distributed:
        preds_l2_dist = [None] * dist.get_world_size()
        preds_l2_norm_dist = [None] * dist.get_world_size()
        preds_euc_cos_dist = [None] * dist.get_world_size()
        labels_dist = [None] * dist.get_world_size()
        dist.barrier()

        dist.all_gather_object(preds_l2_dist, preds_l2)
        dist.all_gather_object(preds_l2_norm_dist, preds_l2_norm)
        dist.all_gather_object(preds_euc_cos_dist, preds_euc_cos)
        dist.all_gather_object(labels_dist, labels)

        preds_l2 = torch.cat(preds_l2_dist, 0)
        preds_l2_norm = torch.cat(preds_l2_norm_dist, 0)
        preds_euc_cos = torch.cat(preds_euc_cos_dist, 0)
        labels = torch.cat(labels_dist, 0)
      

    test_acc_l2 = (float((labels == preds_l2).sum())/len(labels))*100.0
    test_acc_l2_norm = (float((labels == preds_l2_norm).sum())/len(labels))*100.0
    test_acc_dist_cos = (float((labels == preds_euc_cos).sum())/len(labels))*100.0
    print('Test Acc@1_L2 %.3f'%test_acc_l2)
    print('Test Acc@1_COSINE %.3f'%test_acc_l2_norm)
    print('Test Acc@EUC_COS %.3f'%test_acc_dist_cos)
    # all_feats_tsne = TSNE(n_components=2).fit_transform(torch.cat(all_feats, 0))
    # plot_features(all_feats_tsne, labels.data.numpy())
    return test_acc_l2,test_acc_l2_norm


def main(args):
    save_dir = os.path.join(
        'logs',
        'NirvanaFaceLRelu',
        '%s_%s_lr%.6f_Nirvana_Expand%d_Epoch%d_Seed%d_div%d'
        %(
            args.dataset_name,
            args.Network,args.lr, 
            args.Expand, 
            args.epochs, 
            args.Seed, 
            args.div
            ),
        )
    utils.mkdir(save_dir)
    with open(os.path.join(save_dir, 'commandline_args.txt'), 'w') as f:
        json.dump(args.__dict__, f, indent=2)
    writer = SummaryWriter(log_dir=save_dir)
    
    utils.init_distributed_mode(args)
    
    torch.backends.cudnn.benchmark = True
    torch.manual_seed(12345) 
    device = torch.device(args.device)
    #os.environ['CUDA_VISIBLE_DEVICES'] = args.device.split('_')[1]
        # torch.manual_seed(12345)  
    
    data_loader, data_loader_val = dataset_preperation(args)
    args.num_classes = len(data_loader.dataset.classes)
    normalize = T.Normalize(mean=[0.5, 0.5, 0.5],
                                     std=[0.5, 0.5, 0.5])
    train_transform = T.Compose([
            T.Resize((112,112)),
            T.ToTensor(),
            normalize,
        ])
    # lfw, lfw_issame = get_val_data('./data')
    # lfw, lfw_issame = get_val_data('./data')
    # lfw, lfw_issame = get_val_data('./data')
    # lfw, lfw_issame = get_val_data('./data')
    lfw, cfp_ff, cfp_fp, agedb_30, calfw, cplfw, lfw_issame, cfp_ff_issame, cfp_fp_issame, agedb_30_issame, calfw_issame, cplfw_issame = get_val_data('./data')
    print("Creating model")
    # model = IR_50(pretrained=False,input_size=[112,112], num_classes = args.num_classes)
    # if args.num_classes > 2048:
    #     args.feat_dim = args.num_classes-1
    args.feat_dim = args.feat_dim
    # model = models.resnet50(pretrained=False)
    # model = get_network(args.feat_dim, args.num_classes)
    # model = resnet.ResNet18(num_classes=args.num_classes)
    #model = DAMGeneralNew(num_dim=args.feat_dim, num_layers=0, pretrained=args.pretrained)
    #model = IR_50(pretrained=args.pretrained)
    model = iresnet100(pretrained=True)
    model.to(device)
    # args.feat_dim = args.num_classes-1
    print(args)
    
    centerloss = nirvana_hypersphere(
        args.num_classes, 
        args.feat_dim, True, 
        device, Expand=args.Expand
    )
    centerloss.to(device)


    if args.distributed and args.sync_bn:
        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)

    optimizer_center = torch.optim.SGD(
        centerloss.parameters(),
        args.lr,
        momentum=args.momentum,
        weight_decay=2*args.weight_decay,
    )
    optimizer = torch.optim.Adam(model.parameters(), args.lr)
    # lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.lr_step_size, gamma=args.lr_gamma)
    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)

    model_without_ddp = model
    centerloss_without_ddp = centerloss

    if args.distributed:
        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])
        model_without_ddp = model.module
        centerloss = torch.nn.parallel.DistributedDataParallel(centerloss, device_ids=[args.gpu])
        centerloss_without_ddp = centerloss.module
    
    best_val_acc1, best_val_acc1_lfw, val_acc1, val_acc1_lfw, best_val_acc1_ijba, val_acc1_ijba, val_acc1_cfp_ff, best_val_acc1_cfp_ff = 0., 0., 0., 0., 0., 0., 0., 0.
    val_acc1_cfp_fp, best_val_acc1_cfp_fp, val_acc1_agedb_30, best_val_acc1_agedb_30, val_acc1_calfw, best_val_acc1_calfw, val_acc1_cplfw, best_val_acc1_cplfw = 0., 0., 0., 0., 0., 0., 0., 0.
    if args.resume:
        checkpoint = torch.load(args.resume, map_location='cpu')
        model_without_ddp.load_state_dict(checkpoint['model'])
        centerloss_without_ddp.load_state_dict(checkpoint['centerloss'])
        lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])
        args.start_epoch = checkpoint['epoch'] + 1
        best_val_acc1 = checkpoint['best_val_acc1']
        best_val_acc1_lfw = checkpoint['best_val_acc1_lfw']

    if args.test_only:
        val_acc1_lfw, best_threshold_lfw, roc_curve_lfw = perform_val(device, args.feat_dim, 128, model, lfw, lfw_issame)
        val_acc1_cfp_ff, best_threshold_cfp_ff, roc_curve_cfp_ff = perform_val(device, args.feat_dim, 128, model, cfp_ff, cfp_ff_issame)
        val_acc1_cfp_fp, best_threshold_cfp_fp, roc_curve_cfp_fp = perform_val(device, args.feat_dim, 128, model, cfp_fp, cfp_fp_issame)
        val_acc1_agedb_30, best_threshold_agedb_30, roc_curve_agedb_30 = perform_val(device, args.feat_dim, 128, model, agedb_30, agedb_30_issame)
        val_acc1_calfw, best_threshold_calfw, roc_curve_calfw = perform_val(device, args.feat_dim, 128, model, calfw, calfw_issame)
        val_acc1_cplfw, best_threshold_cplfw, roc_curve_cplfw = perform_val(device, args.feat_dim, 128, model, cplfw, cplfw_issame)
        print('%.3f LFW Val., %.3f cfp_ff Val., %.3f cfp_fp, %.3f agedb_30, %.3f calfw, %.3f cplfw'%(val_acc1_lfw,val_acc1_cfp_ff, val_acc1_cfp_fp, val_acc1_agedb_30, val_acc1_calfw, val_acc1_cplfw))

        # return evaluate_majority_voting(model,centerloss, data_loader_val, device, epoch=0,args=args)
        return evaluate_ijba_maj_vot(model, centerloss, train_transform, device, epoch=0,args=args)

    print("Start training")
    start_time = time.time()
    for epoch in range(args.start_epoch, args.epochs):
        if args.distributed:
            dataloader.batch_sampler.set_epoch(epoch)
        #model.train(), centerloss.train()
        acc1,loss = train_one_uhs(model, centerloss, optimizer, optimizer_center, data_loader, device, epoch, args)
        writer.add_scalar('train/acc1', acc1, epoch)
        writer.add_scalar('train/loss', loss, epoch)

        # if(epoch>args.only_centers_upto):
        lr_scheduler.step()
        
        if epoch%args.eval_freq == 0:
            model.eval()
            val_acc1_lfw, best_threshold_lfw, roc_curve_lfw = perform_val(device, args.feat_dim, 128, model, lfw, lfw_issame)
            is_best_lfw = val_acc1_lfw > best_val_acc1_lfw
            best_val_acc1_lfw = max(val_acc1_lfw, best_val_acc1_lfw)
            print('%.3f LFW Val., %.3f LFW Best Val.'%(val_acc1_lfw,best_val_acc1_lfw))
            
            val_acc1_cfp_ff, best_threshold_cfp_ff, roc_curve_cfp_ff = perform_val(device, args.feat_dim, 128, model, cfp_ff, cfp_ff_issame)
            is_best_cfp_ff = val_acc1_cfp_ff > best_val_acc1_cfp_ff
            best_val_acc1_cfp_ff = max(val_acc1_cfp_ff, best_val_acc1_cfp_ff)
            print('%.3f cfp_ff Val., %.3f cfp_ff Best Val.'%(val_acc1_cfp_ff,best_val_acc1_cfp_ff))

            val_acc1_cfp_fp, best_threshold_cfp_fp, roc_curve_cfp_fp = perform_val(device, args.feat_dim, 128, model, cfp_fp, cfp_fp_issame)
            is_best_cfp_fp = val_acc1_cfp_fp > best_val_acc1_cfp_fp
            best_val_acc1_cfp_fp = max(val_acc1_cfp_fp, best_val_acc1_cfp_fp)
            print('%.3f cfp_fp Val., %.3f cfp_fp Best Val.'%(val_acc1_cfp_fp,best_val_acc1_cfp_fp))

            val_acc1_agedb_30, best_threshold_agedb_30, roc_curve_agedb_30 = perform_val(device, args.feat_dim, 128, model, agedb_30, agedb_30_issame)
            is_best_agedb_30 = val_acc1_agedb_30 > best_val_acc1_agedb_30
            best_val_acc1_agedb_30 = max(val_acc1_agedb_30, best_val_acc1_agedb_30)
            print('%.3f agedb_30 Val., %.3f agedb_30 Best Val.'%(val_acc1_agedb_30,best_val_acc1_agedb_30))
            
            val_acc1_calfw, best_threshold_calfw, roc_curve_calfw = perform_val(device, args.feat_dim, 128, model, calfw, calfw_issame)
            is_best_agedb_30 = val_acc1_calfw > best_val_acc1_calfw
            best_val_acc1_calfw = max(val_acc1_calfw, best_val_acc1_calfw)
            print('%.3f calfw Val., %.3f calfw Best Val.'%(val_acc1_calfw,best_val_acc1_calfw))

            # val_acc1_ijba = evaluate_ijba_maj_vot(model, centerloss, train_transform, device, epoch=epoch,args=args)
            # is_best_ijba = val_acc1_ijba > best_val_acc1_ijba
            # best_val_acc1_ijba= max(val_acc1_ijba, best_val_acc1_ijba)
            # print('%.3f IJBA Val., %.3f IJBA Best Val.'%(val_acc1_ijba,best_val_acc1_ijba))              
         
            val_acc1_cplfw, best_threshold_cplfw, roc_curve_cplfw = perform_val(device, args.feat_dim, 128, model, cplfw, cplfw_issame)
            is_best_cplfw = val_acc1_cplfw > best_val_acc1_cplfw
            best_val_acc1_cplfw= max(val_acc1_cplfw, best_val_acc1_cplfw)
            print('%.3f cplfw Val., %.3f cplfw Best Val.'%(val_acc1_cplfw,best_val_acc1_cplfw))              
         
            # val_acc1,val_acc1_fc = evaluate_majority_voting(model,centerloss, data_loader_val, device, epoch,args=args)
            # is_best = val_acc1 > best_val_acc1
            # best_val_acc1 = max(val_acc1, best_val_acc1)
            # writer.add_scalar('val/acc1', val_acc1, epoch)
            # writer.add_scalar('val/best_acc1', best_val_acc1, epoch)
            # print('%.3f Data Val., %.3f Data Best Val.'%(val_acc1,best_val_acc1))
            
            checkpoint = {
                'model': model_without_ddp.state_dict(),
                'centerloss': centerloss_without_ddp.state_dict(),
                'optimizer': optimizer.state_dict(),
                'lr_scheduler': lr_scheduler.state_dict(),
                'epoch': epoch,
                'val_acc1': val_acc1,
                # 'val_acc1_fc':val_acc1_fc,
                'best_val_acc1': best_val_acc1,
                'val_acc1_lfw': val_acc1_lfw,
                'best_val_acc1_lfw': best_val_acc1_lfw,
                'args': args}
            utils.save_on_master(
                checkpoint,
                os.path.join(save_dir, 'model_{}.pth'.format(epoch)))
            if(is_best_lfw):
                utils.save_on_master(
                    checkpoint,
                    os.path.join(save_dir, 'best_checkpoint.pth'))
                is_best=False

    total_time = time.time() - start_time
    total_time_str = str(datetime.timedelta(seconds=int(total_time)))
    print('Training time {}'.format(total_time_str))
    writer.close()
    
def parse_args():
    import argparse
    parser = argparse.ArgumentParser(description='PyTorch Classification Training')
    parser.add_argument('--device', default='cuda_0', help='device ex. cuda_7, cuda_6')
    parser.add_argument('-b', '--batch-size', default=64, type=int)
    parser.add_argument('--start-epoch', default=0, type=int, metavar='N',
                        help='start epoch')
    parser.add_argument('-d', '--dataset_name', default='VGGFace2', metavar='N',
                        help='CIFAR10, CIFAR100, car196, MNIST, VGGFace2 ')
    parser.add_argument('-n', '--Network', default='ResNet50', metavar='N',
                        help='ResNet18, ResNet50')
    parser.add_argument('--epochs', default=100, type=int, metavar='N',
                        help='number of total epochs to run')
    parser.add_argument('--div', default=10, type=int, metavar='N',
                        help='division number for Nirvana Hinge loss')
    parser.add_argument('--num_classes', default=200, type=int, metavar='N',
                        help='number of classes')
    parser.add_argument('--Expand', default=32, type=int, metavar='N',
                        help='Expand factor of centers')
    parser.add_argument('--Seed', default=0, type=int, metavar='N',
                        help='Seed')
    parser.add_argument('--feat_dim', default=512, type=int, metavar='N',
                        help='feature dimension of the model')
    parser.add_argument('-j', '--workers', default=0, type=int, metavar='N',
                        help='number of data loading workers (default: 16)')
    parser.add_argument('--lr', default=0.00001, type=float, help='initial learning rate')
    parser.add_argument('--momentum', default=0.9, type=float, metavar='M',
                        help='momentum')
    parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,
                        metavar='W', help='weight decay (default: 1e-4)',
                        dest='weight_decay')
    parser.add_argument('--lr-step-size', default=50, type=int, help='decrease lr every step-size epochs')
    parser.add_argument('--lr-gamma', default=0.1, type=float, help='decrease lr by a factor of lr-gamma')
    parser.add_argument('--lamda', default=0.5, type=float, help='decrease lr by a factor of lr-gamma')
    parser.add_argument('--print-freq', default=500, type=int, help='print frequency')
    parser.add_argument('--eval-freq', default=1, type=int, help='print frequency')
    parser.add_argument('--resume', default='', help='resume from checkpoint')
    parser.add_argument('--test_only', default=False, help='Only Test the model')
    parser.add_argument('--pretrained', default=True, help='True or False')

    parser.add_argument(
        "--sync-bn",
        dest="sync_bn",
        help="Use sync batch norm",
        action="store_true",
    )
    # distributed training parameters
    parser.add_argument('--world-size', default=1, type=int,
                        help='number of distributed processes')
    parser.add_argument('--dist-url', default='env://', help='url used to set up distributed training')

    args = parser.parse_args()
    return args

if __name__ == "__main__":
    args = parse_args()
    main(args)
